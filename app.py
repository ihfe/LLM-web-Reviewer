from openai import OpenAI
from get_paper_ import Paper
import jieba
from io import BytesIO
import time
import openai, tenacity
import tiktoken
import PyPDF2
import gradio as gr
from toolbox import get_conf
from themes.theme import load_dynamic_theme,js_code_for_css_changing
AVAIL_THEMES, THEME=get_conf('AVAIL_THEMES', 'THEME')

import os
os.environ["no_proxy"] = "localhost,127.0.0.1,::1"

# æŒ‡å®šå†å²è®°å½•æ–‡ä»¶çš„ç›®å½•
history_dir = 'history'

# è·å–ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å
def get_files_list():
    # åªåˆ—å‡º .txt æ–‡ä»¶
    files = [f for f in os.listdir(history_dir) if f.endswith('.txt')]
    return files


# è¯»å–æŒ‡å®šæ–‡ä»¶çš„å†…å®¹
# è¯»å–æŒ‡å®šæ–‡ä»¶çš„å†…å®¹
def load_file_content(file_name):
    file_path = os.path.join(history_dir, file_name)
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    return content, file_path


# ä¸‹è½½æŒ‡å®šæ–‡ä»¶
def download_file(file_name):
    file_path = os.path.join(history_dir, file_name)
    return file_path


def contains_chinese(text):
    for ch in text:
        if u'\u4e00' <= ch <= u'\u9fff':
            return True
    return False

#æ–‡æœ¬ text æŒ‰ç…§æ¢è¡Œç¬¦ \n åˆ†å‰²æˆå¤šè¡Œæ–‡æœ¬ï¼Œå¹¶å­˜å‚¨åœ¨ lines åˆ—è¡¨ä¸­
def insert_sentence(text, sentence, interval):
    lines = text.split('\n')
    new_lines = []

    for line in lines:
        if contains_chinese(line):
            words = list(jieba.cut(line))
            separator = ''
        else:
            words = line.split()
            separator = ' '

        new_words = []
        count = 0

        for word in words:
            new_words.append(word)
            count += 1

            if count % interval == 0:
                new_words.append(sentence)

        new_lines.append(separator.join(new_words))

    return '\n'.join(new_lines)


with open('txt_file/result_zh.txt', 'r', encoding='UTF-8') as file:  # è¯»å–ç‰¹å®šçš„å®¡ç¨¿æ ¼å¼
    result = file.read()

with open('txt_file/computer_eng.txt', 'r', encoding='UTF-8') as file:  # è¯»å–ç‰¹å®šçš„å®¡ç¨¿æ ¼å¼
    computer = file.read()

with open('txt_file/Instract.txt', 'r', encoding='UTF-8') as file:  # è¯»å–ç‰¹å®šçš„å®¡ç¨¿æ ¼å¼
    logic = file.read()
# prompt_computer = (
#     f"-You are a professional reviewer in the computer science and Artificial intelligence realm. "
#     f"-You need follow the prompt:{computer} when you are reviewing the dissertation. "
# )

prompt_computer = (
    f"-You are a professional reviewer in the computer science and Artificial intelligence realm. "
    f"-You need follow the prompt:{computer} when you are reviewing the dissertation. "
    f"-Please NOTE: Finally,you should give the author your review result,please refer to {result}.This is very important"
)

# openai.api_key = 'sk-1SWMJzlmDYazLQQzF1B7BfBbB83245FaBdA706E5752e5623'  # openai api, api2d api
# openai.api_base ='https://api.lqqq.ltd/v1'  # apiåœ°å€
# models = ['gpt-3.5-turbo', 'gpt-4']
api_key = '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'  # openai api, api2d api
client = OpenAI(api_key=api_key)
models = ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k','gpt-4']


# å®šä¹‰Reviewerç±»
class Reviewer:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®å±æ€§
    def __init__(self, model, review_prompt, paper_pdf, language):
        self.model = model
        if review_prompt == 'å·¥ç§‘ç±»':
            self.review_prompt = prompt_computer
        self.language = language
        self.paper_pdf = paper_pdf
        self.max_token_num = 12000
        self.encoding = tiktoken.get_encoding("gpt2")

    def review_by_chatgpt(self, paper_list):
        htmls = []
        for paper_index, paper in enumerate(paper_list):
            sections_of_interest = self.stage_1(paper)
            # extract the essential parts of the paper
            text = ''
            text += '[Title]:' + paper.title + '. '
            text += '[Abstract]: ' + paper.section_texts['Abstract']
            intro_title = next((item for item in paper.section_names if 'introduction' in item.lower()), None)
            if intro_title is not None:
                text += '[Introduction]: ' + paper.section_texts[intro_title]
            # Similar for conclusion section
            conclusion_title = next((item for item in paper.section_names if 'conclusion' in item), None)
            if conclusion_title is not None:
                text += '[Conclusion]: ' + paper.section_texts[conclusion_title]
            for heading in sections_of_interest:
                if heading in paper.section_names:
                    text += heading + ': ' + paper.section_texts[heading]
            chat_review_text,usage = self.chat_review(text=text)
        #     review_result, review_usage = self.chat_review(text=text)
        #     messages = [
        #         {"role": "system",
        #          "content": f"I will give you a paragraph of text"
        #                     f"and you need to check if the text meets my template:{computer}"
        #                     f"If it does not, you need to modify the format of my text to meet the template format."
        #                     f"And if it does,don't change it ,just show my text to me"
        #                     f"be sure to give me your answer in {self.language}"
        #          },
        #         {"role": "user",
        #          "content": f"This is my text:{review_result}"
        #          }
        #     ]
        #     response = client.chat.completions.create(
        #         model=self.model,
        #         messages=messages,
        #         temperature=0.5
        #     )
        #     result = ''
        #     for choice in response.choices:
        #         result += choice.message.content
        # return result, review_usage
        return chat_review_text,usage
        # text = self.extract_chapter(self.paper_pdf)
        # chat_review_text, total_token_used = self.chat_review(text=text)
        # return chat_review_text, total_token_used

    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)

    def chat_review(self, text):
        # openai.api_key = 'sk-1SWMJzlmDYazLQQzF1B7BfBbB83245FaBdA706E5752e5623'  # openai api, api2d api
        openai.api_key = api_key
        review_prompt_token = 1000
        try:
            text_token = len(self.encoding.encode(text))
        except:
            text_token = 13000
        input_text_index = int(len(text) * (self.max_token_num - review_prompt_token) / (text_token + 1))
        input_text = "This is the paper for your review:" + text[:input_text_index]

        messages = [
            {"role": "system",
             "content": "-You are a professional reviewer. "
                        f"-I will give you a paper. when you review the paper, you must refer to the {logic} and then give your review answer. "
                        f"-ATTENTION: your answer must comply to the template:" + self.review_prompt + "."
                        "-Be careful: Make sure to use {} answers".format(self.language)
             },
            {"role": "user", "content": input_text + ". ATTENTION!! YOU must translate the output into {}.".format(self.language)},
        ]
        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.5
            )
            result = ''
            for choice in response.choices:
                result += choice.message.content
            result = insert_sentence(result, '**Generated by ChatGPT, no copying allowed!**', 100)
            result += "\n\nâš ä¼¦ç†å£°æ˜/Ethics statementï¼š\n--ç¦æ­¢ç›´æ¥å¤åˆ¶ç”Ÿæˆçš„è¯„è®ºç”¨äºä»»ä½•è®ºæ–‡å®¡ç¨¿å·¥ä½œï¼\n--Direct copying of generated comments for any paper review work is prohibited!"
            usage = response.usage.total_tokens
        except Exception as e:
            # å¤„ç†å…¶ä»–çš„å¼‚å¸¸
            result = "âš ï¼šéå¸¸æŠ±æ­‰>_<ï¼Œç”Ÿäº†ä¸€ä¸ªé”™è¯¯ï¼š" + str(e)
            usage = 'xxxxx'
        print("********" * 10)
        print(result)
        print("********" * 10)
        return result, usage

    def stage_1(self, paper):
        htmls = []
        text = ''
        text += 'Title: ' + paper.title + '. '
        text += 'Abstract: ' + paper.section_texts['Abstract']
        text_token = len(self.encoding.encode(text))#text_tokenï¼š272
        if text_token > self.max_token_num/2 - 800:
            input_text_index = int(len(text)*((self.max_token_num/2)-800)/text_token)#ï¼Ÿ
            text = text[:input_text_index]
        openai.api_key = api_key
        messages = [
            {"role": "system",
             "content": f"I will give you a paper. You need to review this paper and discuss the novelty and originality of ideas, correctness, clarity, the significance of results, potential impact and quality of the presentation. "
                        f"Due to the length limitations, I am only allowed to provide you the abstract, introduction, conclusion and at most two sections of this paper."
                        f"Now I will give you the title and abstract and the headings of potential sections. "
                        f"You need to reply at most two headings. Then I will further provide you the full information, includes aforementioned sections and at most two sections you called for.\n\n"
                        f"Title: {paper.title}\n\n"
                        f"Abstract: {paper.section_texts['Abstract']}\n\n"
                        f"Potential Sections: {paper.section_names[2:-1]}\n\n"
                        f"Follow the following format to output your choice of sections:"
                        f"{{chosen section 1}}, {{chosen section 2}}\n\n"},
            {"role": "user", "content": text},
        ]
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        print(result)
        return result.split(',')

    # def extract_chapter(self, pdf_path):
    #     file_object = BytesIO(pdf_path)
    #     pdf_reader = PyPDF2.PdfReader(file_object)
    #     # è·å–PDFçš„æ€»é¡µæ•°
    #     num_pages = len(pdf_reader.pages)
    #     # åˆå§‹åŒ–æå–çŠ¶æ€å’Œæå–æ–‡æœ¬
    #     extraction_started = False
    #     extracted_text = ""
    #     # éå†PDFä¸­çš„æ¯ä¸€é¡µ
    #     for page_number in range(num_pages):
    #         page = pdf_reader.pages[page_number]
    #         page_text = page.extract_text()
    #         # å¼€å§‹æå–
    #         extraction_started = True
    #         page_number_start = page_number
    #         # å¦‚æœæå–å·²å¼€å§‹ï¼Œå°†é¡µé¢æ–‡æœ¬æ·»åŠ åˆ°æå–æ–‡æœ¬ä¸­
    #         if extraction_started:
    #             extracted_text += page_text
    #             # åœæ­¢æå–
    #             if page_number_start + 1 < page_number:
    #                 break
    #     return extracted_text


def main(model, review_prompt, path, language):
    start_time = time.time()
    comments = ''
    output2 = ''
    if not model or not review_prompt or not path:
        comments = "âš ï¼šè®ºæ–‡æ ¼å¼ä¸æ˜ç¡®ï¼Œè¯·æ£€æµ‹ï¼"
        output2 = "âš ï¼šè®ºæ–‡æ ¼å¼ä¸æ˜ç¡®ï¼Œè¯·æ£€æµ‹ï¼"
    # åˆ¤æ–­PDFæ–‡ä»¶
    else:
        # åˆ›å»ºä¸€ä¸ªReaderå¯¹è±¡
        reviewer1 = Reviewer(model, review_prompt, path.name, language)
        paper_list=[]
        paper_list.append(Paper(path=path.name))  #[<get_paper_from_pdf.Paper object at 0x0000020B2060C0A0>]
        # å¼€å§‹åˆ¤æ–­æ˜¯è·¯å¾„è¿˜æ˜¯æ–‡ä»¶ï¼š
        comments, total_token_used = reviewer1.review_by_chatgpt(paper_list=paper_list)#b'%PDF-1.5\n%\x8f\n136 0 obj\n<< /Filter /FlateDecode /Length 4732 >>\nstream\nx\
        time_used = time.time() - start_time
        output2 = "ä½¿ç”¨tokenæ•°ï¼š" + str(total_token_used) + "\nèŠ±è´¹æ—¶é—´ï¼š" + str(round(time_used, 2)) + "ç§’"
        txt_name = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime()) + ".txt"
        # ä½¿ç”¨ 'with' è¯­å¥æ‰“å¼€æ–‡ä»¶ï¼Œç¡®ä¿è‡ªåŠ¨å…³é—­æ–‡ä»¶
        with open("history/"+txt_name, 'w', encoding='utf-8') as file:
            # å†™å…¥ä¸­æ–‡æ–‡æœ¬
            file.write(comments)
    return comments, output2


# æ ‡é¢˜
title = "ğŸ¤–åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è™šæ‹Ÿå®¡ç¨¿äººğŸ¤–"
# # æè¿°
#
# description = '''<div align='left'>
# <strong>è¿™æ˜¯ä¸€æ¬¾åŸºäºChatGPT-3.5çš„APIå¼€å‘çš„æ™ºèƒ½è®ºæ–‡åˆ†æä¸å»ºè®®åŠ©æ‰‹ã€‚</strong>ï¼š
# </div>
# '''
# åˆ›å»º Gradioç•Œé¢

with gr.Blocks(title="ğŸ¤–åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è™šæ‹Ÿå®¡ç¨¿äººğŸ¤–",theme="default") as demo:
    secret_css = gr.Textbox(visible=False)
    gr.Markdown('''<div align='center'>
<h1>ğŸ¤–åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è™šæ‹Ÿå®¡ç¨¿äºº</h1></strong>
</div>
<h5>è¿™æ˜¯ä¸€æ¬¾åŸºäºChatGPTğŸ¤–çš„APIå¼€å‘çš„æ™ºèƒ½è®ºæ–‡åˆ†æä¸å®¡ç¨¿åŠ©æ‰‹ğŸ“–ã€‚</h5>
    â­â­â­<strong>å»ºè®®:</strong>
    <ul>
      <li>å»ºè®®æ™®é€šç”¨æˆ·æ¯ç¯‡ç¨¿ä»¶ğŸ“š<strong>æäº¤2-3æ¬¡</strong>ç»¼åˆè¯„åˆ¤å¤§è¯­è¨€æ¨¡å‹ç»™å‡ºçš„ç»“æœ</li>
      <li>å‡å¦‚å¤šæ¬¡æäº¤çš„æ„è§åˆ†æ­§ä¸¥é‡ï¼Œå»ºè®®ä¿®æ”¹ç¨¿ä»¶</li>
      <li>å¯¹äº<strong>åŒ»å­¦ç±»</strong>ğŸš‘ğŸ’Šæˆ–è€…<strong>è‰ºæœ¯ç±»</strong>ğŸ¨å›¾ç‰‡è¾ƒå¤šçš„è®ºæ–‡ï¼Œæ¨èä½¿ç”¨æ”¯æŒå¤šæ¨¡æ€çš„gpt4ä½œä¸ºè™šæ‹Ÿå®¡ç¨¿äºº</li>
    </ul>
''')
    with gr.Row():
        with gr.Tab("å®¡ç¨¿",elem_id="review-panel"):
            with gr.Column():
                model = gr.Radio(models,label="è¯·é€‰æ‹©ä½¿ç”¨æ¨¡å‹", interactive=True)
                prompt = gr.Dropdown(
                           choices=[
                               "å·¥ç§‘ç±»",
                               "åŒ»å­¦ç±»",
                               "ç”Ÿç‰©ç±»",
                               "åŒ–å­¦ç±»",
                               "è½¦è¾†å·¥ç¨‹ç±»"],label="Prompts", info="æ–‡ç« æ‰€å±çš„ç±»åˆ«", allow_custom_value=True)
                File_loader = gr.File(label="è¯·ä¸Šä¼ è®ºæ–‡PDFæ–‡ä»¶(è¯·åŠ¡å¿…ç­‰pdfä¸Šä¼ å®Œæˆåå†ç‚¹å‡»å¼€å§‹å®¡ç¨¿ï¼)", type='filepath')
                langan = gr.Radio(choices=["English", "Chinese", "French", "German", "Japenese"],
                                    label="é€‰æ‹©è¾“å‡ºè¯­è¨€")
            with gr.Column():
                outputs = [gr.Textbox(lines=20, label="åˆ†æç»“æœ"),
                                                      gr.Textbox(lines=2, label="èµ„æºç»Ÿè®¡")]
            btn = gr.Button("å¼€å§‹å®¡ç¨¿")
            btn.click(fn=main, inputs=[model, prompt, File_loader, langan], outputs=outputs)
        with gr.Tab("èŠå¤©",elem_id="interact-panel"):
            chat_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå’Œè®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„å®¡ç¨¿äººï¼Œç”¨æˆ·ä¼šå¯¹ä½ æå‡ºé—®é¢˜ï¼Œè¯·ä½ ä»¥ä¸“ä¸šæ­£å¼çš„è¯­è¨€ï¼Œä¿æŒä¸­ç«‹çš„æ€åº¦å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚å›å¤ç”¨æˆ·é—®é¢˜æ—¶è¯·å†ä¸‰æ€è€ƒï¼Œç¡®ä¿å›ç­”çš„æ­£ç¡®ã€‚"
            # å®šä¹‰ä¸€ä¸ªæè¿°æœºå™¨äººçš„è§’è‰²ã€è¡Œä¸ºå’Œè¯­æ°”çš„æç¤º
            role_prompt = {
                "role": "system",
                "content":chat_prompt
            }
            # åˆå§‹åŒ–å¯¹è¯å†å²æ ¼å¼ï¼ŒåŒ…æ‹¬è§’è‰²æç¤º
            history_openai_format = [role_prompt]

            def predict(message, history):
                for human, assistant in history:
                    history_openai_format.append({"role": "user", "content": human})
                    history_openai_format.append({"role": "assistant", "content": assistant})
                history_openai_format.append({"role": "user", "content": message})

                response = client.chat.completions.create(
                    model='gpt-3.5-turbo',
                    messages=history_openai_format,
                    temperature=1.0,
                    stream=True
                )

                partial_message = ""
                for chunk in response:
                    if chunk.choices[0].delta.content is not None:
                        partial_message = partial_message + chunk.choices[0].delta.content
                        yield partial_message

            gr.ChatInterface(predict,examples=["æˆ‘ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥åŠ¨é‡é¡¹ä»¥åŠ é€Ÿæ”¶æ•›ï¼Œè¯·ä½ è¯„ä»·è¯¥æ–¹æ³•çš„ç§‘å­¦æ€§ï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚"],theme=gr.themes.Soft())
        with gr.Tab("å†å²è®°å½•", elem_id="history-panel"):
            with gr.Column(scale=1):
                # æ–‡ä»¶å†…å®¹æ˜¾ç¤º
                file_content = gr.Textbox(label="æ–‡ä»¶å†…å®¹", lines=20, interactive=False, elem_id="file_content")
                # æ–‡ä»¶è·¯å¾„ï¼ˆéšè—ï¼‰
                file_path = gr.File(label="")
                # ä¸‹è½½æŒ‰é’®ç‚¹å‡»äº‹ä»¶ï¼Œå°†æ–‡ä»¶è·¯å¾„ä½œä¸ºæŒ‰é’®çš„è¾“å‡º

            with gr.Column(scale=2):
                # è·å–å†å²è®°å½•æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° file_list åˆ—
                files = get_files_list()

            for file_name in files:
                with gr.Row():
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºä¸€ä¸ªæŒ‰é’®
                    file_button = gr.Button(file_name)
                    # ä¸ºæŒ‰é’®æ·»åŠ äº‹ä»¶ï¼Œå½“ç‚¹å‡»æŒ‰é’®æ—¶ï¼ŒåŠ è½½æ–‡ä»¶å†…å®¹
                    file_button.click(load_file_content, inputs=file_button, outputs=[file_content, file_path])
        with gr.Tab("ç•Œé¢å¤–è§‚", elem_id="beautiful-panel"):
            theme_dropdown = gr.Dropdown(AVAIL_THEMES, value=THEME, label="æ›´æ¢UIä¸»é¢˜")
            gr.Markdown("è¯·æ›´æ¢ç•Œé¢å¤–è§‚")

    def on_theme_dropdown_changed(theme, secret_css):
        adjust_theme, css_part1, _, adjust_dynamic_theme = load_dynamic_theme(theme)
        if adjust_dynamic_theme:
            css_part2 = adjust_dynamic_theme._get_theme_css()
        else:
            css_part2 = adjust_theme()._get_theme_css()
        return css_part2 + css_part1


    theme_handle = theme_dropdown.select(on_theme_dropdown_changed, [theme_dropdown, secret_css], [secret_css])
    theme_handle.then(
        None,
        [secret_css],
        None,
        js=js_code_for_css_changing
    )
demo.queue().launch()
